{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9JV4JSdbGnrn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWeSCrmTE57B"
      },
      "outputs": [],
      "source": [
        "# 導入工作必要函式庫\n",
        "from IPython.display import display, Javascript, Image\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode, b64encode\n",
        "import cv2\n",
        "import numpy as np\n",
        "import PIL\n",
        "import io\n",
        "import html\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 轉換JavaScript影像物件變成OpenCV格式影像函式\n",
        "\n",
        "輸入參數：  \n",
        "js_reply : JavaScript物件，內含從網路攝影像取得之影像  \n",
        "\n",
        "回返結果:  \n",
        "img : OpenCV BGR格式之影像  "
      ],
      "metadata": {
        "id": "qUb1eSkYMNWT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def js_to_image(js_reply):\n",
        "  # 解碼成 base64 格式影像\n",
        "  image_bytes = b64decode(js_reply.split(',')[1])\n",
        "  # 轉換影像變成 Numpy 格式\n",
        "  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
        "  # 解碼 Numpy格式到 OpenCV BGR 影像格式\n",
        "  img = cv2.imdecode(jpg_as_np, flags=1)\n",
        "\n",
        "  return img"
      ],
      "metadata": {
        "id": "nLxYK8ccMMI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 自定義OpenCV影像處理函式\n",
        "\n",
        "可自行加入任意處理OpenCV函式，這裡僅使用一個很簡單的影像色彩反轉為例。  \n",
        "註：JavaScript預設取得及顯示彩色影像格式為RGB，若使用BGR格式就會產生色彩反轉。  \n",
        "\n",
        "輸入參數：  \n",
        "img : OpenCV BGR 格式之輸入影像\n",
        "\n",
        "回返結果:  \n",
        "bgr : OpenCV BGR 格式之輸出影像  \n"
      ],
      "metadata": {
        "id": "nynzo8OaSUxD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def img_process(img):\n",
        "    \n",
        "    bgr = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "    return bgr"
      ],
      "metadata": {
        "id": "leMEPsnYSXHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Google Colab 網路攝影機取像函式\n",
        "\n",
        "本函式由Colab左側選單中「程式碼片段」新增「Camera Capture」而得。  \n",
        "\n",
        "預設呼叫後會產生一個「Capture」按鍵和一個視窗顯示網路攝影機(Webcam)目前取得的連續影像。  \n",
        "\n",
        "按下「Capture」鍵取得影像後，可使用OpenCV來進行任意影像處理及繪製線、框、文字到影像上，再顯示結果。    "
      ],
      "metadata": {
        "id": "V8pPpB-iGmtH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from IPython.display import display, Javascript\n",
        "#from google.colab.output import eval_js\n",
        "#from base64 import b64decode\n",
        "\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "\n",
        "  # 取得JavaScript產生的影像物件\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "\n",
        "  # 取得影像並加入自定義之OpenCV影像處理程式\n",
        "  img = js_to_image(data)\n",
        "  result_img = img_process(img)\n",
        "\n",
        "  ## 將 JavaScript 取得的影像解碼成 base64 格式\n",
        "  #binary = b64decode(data.split(',')[1])\n",
        "\n",
        "  ## 將檔案寫入名為 filename 的檔案中\n",
        "  #with open(filename, 'wb') as f:\n",
        "  #  f.write(binary)\n",
        "  #return filename\n",
        "\n",
        "  # 可改用 OpenCV imwrite() 函式取代原有檔案寫入動作，可省去轉換 base64 格式動作\n",
        "  cv2.imwrite(\"original.jpg\", img) # \n",
        "  cv2.imwrite(filename, result_img)\n",
        "  return filename"
      ],
      "metadata": {
        "id": "YY6a9QzmE_hB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 等待網路攝影機取像後進行影像處理及顯示結果\n",
        "\n",
        "\n",
        "按下「Capture」會結束程式並將最後一張影像存入檔案「photo.jpg」中，此為預設檔名亦可於呼叫時另行指定。  \n",
        "\n",
        "同時會執行自定義影像處理函式，並顯示原始及處理後影像內容。  "
      ],
      "metadata": {
        "id": "4nBIinh4xXeh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from IPython.display import Image\n",
        "try:  \n",
        "  # 啟動網路攝影機連續取像，按下「Capture」後，取得靜態影像，經自定義影像處理後並顯示，預設存檔檔名 photo.jpg\n",
        "  result_filename = take_photo()\n",
        "\n",
        "  # 顯示網路攝影機取得之原始影像\n",
        "  original_filename = 'original.jpg'\n",
        "  print('Original Image : {}'.format(original_filename))\n",
        "  display(Image(original_filename))\n",
        "\n",
        "  # 顯示影像處理後之結果影像\n",
        "  print('Processed Image : {}'.format(result_filename))\n",
        "  display(Image(result_filename))  \n",
        "\n",
        "except Exception as err:\n",
        "  # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "  # grant the page permission to access it.\n",
        "  print(str(err))"
      ],
      "metadata": {
        "id": "8RPb-5hqE_hC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**透過以上程式會發現，連續取像過程並不會執行自定義影像處理，只有最後按下「Capture」鍵後才會執行及顯示自定義影像處理函式，所以上述作法只適合靜態結果輸出。**  \n",
        "\n",
        "接著說明如何在網路攝影機取像過程中就直接執行自定義影像處理的方式。  \n",
        "\n",
        "由於Colab是雲端服務，所以本地端網路攝影機取得的影像要先上傳，再透過網頁元件顯示獲取的影像，收到後才能再提供給其它程式（如OpenCV, PIL...)進行處理分析。而計算所得的結果（如線、框、文字）需要畫在一個具有透明圖層（Alpha Channel)的影像上，即產生一張去背影像，再套疊到下一個擷取到的影格上，而非目前的影格，所以顯示出來的結果會有一個影格的延遲。若遇到被偵測的物件移動較快時，顯示上會有跟不上的情況產生，是正常的。  \n",
        "\n"
      ],
      "metadata": {
        "id": "DuhmpmUKqNLN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 從網路攝影機取得及顯示連續串流影像相關函式\n",
        "\n",
        "video_stream() 設定串流影像顯示環境（包含串流影像顯示及上下文字說明區），並啟動網路攝影機連續取像顯示  \n",
        "removeDom() 移除網頁文件物件模型  \n",
        "onAnimationFrame() 繪製套疊影像到影格上  \n",
        "createDom() 建立網頁文件物件模型  \n",
        "stream_frame() 取得串流影格內容  \n",
        "video_frame() 取得目前影格內容  \n",
        "\n",
        "參考資料來源： https://colab.research.google.com/drive/1QnC7lV7oVFk5OZCm75fqbLAfD9qBy9bw?usp=sharing"
      ],
      "metadata": {
        "id": "1puuuE3x6Hno"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# JavaScript to properly create our live video stream using our webcam as input\n",
        "def video_stream():\n",
        "  js = Javascript('''\n",
        "    var video;\n",
        "    var div = null;\n",
        "    var stream;\n",
        "    var captureCanvas;\n",
        "    var imgElement;\n",
        "    var labelElement;\n",
        "    \n",
        "    var pendingResolve = null;\n",
        "    var shutdown = false;\n",
        "    \n",
        "    function removeDom() {\n",
        "       stream.getVideoTracks()[0].stop();\n",
        "       video.remove();\n",
        "       div.remove();\n",
        "       video = null;\n",
        "       div = null;\n",
        "       stream = null;\n",
        "       imgElement = null;\n",
        "       captureCanvas = null;\n",
        "       labelElement = null;\n",
        "    }\n",
        "    \n",
        "    function onAnimationFrame() {\n",
        "      if (!shutdown) {\n",
        "        window.requestAnimationFrame(onAnimationFrame);\n",
        "      }\n",
        "      if (pendingResolve) {\n",
        "        var result = \"\";\n",
        "        if (!shutdown) {\n",
        "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
        "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
        "        }\n",
        "        var lp = pendingResolve;\n",
        "        pendingResolve = null;\n",
        "        lp(result);\n",
        "      }\n",
        "    }\n",
        "    \n",
        "    async function createDom() {\n",
        "      if (div !== null) {\n",
        "        return stream;\n",
        "      }\n",
        "\n",
        "      div = document.createElement('div');\n",
        "      div.style.border = '2px solid black';\n",
        "      div.style.padding = '3px';\n",
        "      div.style.width = '100%';\n",
        "      div.style.maxWidth = '600px';\n",
        "      document.body.appendChild(div);\n",
        "      \n",
        "      const modelOut = document.createElement('div');\n",
        "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
        "      labelElement = document.createElement('span');\n",
        "      labelElement.innerText = 'No data';\n",
        "      labelElement.style.fontWeight = 'bold';\n",
        "      modelOut.appendChild(labelElement);\n",
        "      div.appendChild(modelOut);\n",
        "           \n",
        "      video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      video.width = div.clientWidth - 6;\n",
        "      video.setAttribute('playsinline', '');\n",
        "      video.onclick = () => { shutdown = true; };\n",
        "      stream = await navigator.mediaDevices.getUserMedia(\n",
        "          {video: { facingMode: \"environment\"}});\n",
        "      div.appendChild(video);\n",
        "\n",
        "      imgElement = document.createElement('img');\n",
        "      imgElement.style.position = 'absolute';\n",
        "      imgElement.style.zIndex = 1;\n",
        "      imgElement.onclick = () => { shutdown = true; };\n",
        "      div.appendChild(imgElement);\n",
        "      \n",
        "      const instruction = document.createElement('div');\n",
        "      instruction.innerHTML = \n",
        "          '<span style=\"color: red; font-weight: bold;\">' +\n",
        "          'When finished, click here or on the video to stop this demo</span>';\n",
        "      div.appendChild(instruction);\n",
        "      instruction.onclick = () => { shutdown = true; };\n",
        "      \n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      captureCanvas = document.createElement('canvas');\n",
        "      captureCanvas.width = 640; //video.videoWidth;\n",
        "      captureCanvas.height = 480; //video.videoHeight;\n",
        "      window.requestAnimationFrame(onAnimationFrame);\n",
        "      \n",
        "      return stream;\n",
        "    }\n",
        "    \n",
        "    async function stream_frame(label, imgData) {\n",
        "      if (shutdown) {\n",
        "        removeDom();\n",
        "        shutdown = false;\n",
        "        return '';\n",
        "      }\n",
        "\n",
        "      var preCreate = Date.now();\n",
        "      stream = await createDom();\n",
        "      \n",
        "      var preShow = Date.now();\n",
        "      if (label != \"\") {\n",
        "        labelElement.innerHTML = label;\n",
        "      }\n",
        "            \n",
        "      if (imgData != \"\") {\n",
        "        var videoRect = video.getClientRects()[0];\n",
        "        imgElement.style.top = videoRect.top + \"px\";\n",
        "        imgElement.style.left = videoRect.left + \"px\";\n",
        "        imgElement.style.width = videoRect.width + \"px\";\n",
        "        imgElement.style.height = videoRect.height + \"px\";\n",
        "        imgElement.src = imgData;\n",
        "      }\n",
        "      \n",
        "      var preCapture = Date.now();\n",
        "      var result = await new Promise(function(resolve, reject) {\n",
        "        pendingResolve = resolve;\n",
        "      });\n",
        "      shutdown = false;\n",
        "      \n",
        "      return {'create': preShow - preCreate, \n",
        "              'show': preCapture - preShow, \n",
        "              'capture': Date.now() - preCapture,\n",
        "              'img': result};\n",
        "    }\n",
        "    ''')\n",
        "\n",
        "  display(js)\n",
        "  \n",
        "def video_frame(label, bbox):\n",
        "  data = eval_js('stream_frame(\"{}\", \"{}\")'.format(label, bbox))\n",
        "  return data"
      ],
      "metadata": {
        "id": "PRwOslZpynKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 自定義即時影像處理函式\n",
        "\n",
        "可任意加入自定義OpenCV, PIL影像處理函式，這裡以隨機繪製一個方塊（空心紅框或實心黃方塊）作為範例。\n",
        "\n",
        "輸入參數：  \n",
        "img : OpenCV BGR 格式之輸入影像\n",
        "\n",
        "回返結果:  \n",
        "bgra : OpenCV BGRA 格式之輸出影像 "
      ],
      "metadata": {
        "id": "9ZKlXbViGbYP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def realtime_process(img):\n",
        "   # 產生一個具透明圖層的影像，即 OpenCV BGRA 格式。\n",
        "   # [:,:,3]即為透明層設定，初始值為0，即為全透明。\n",
        "   bgra = np.zeros([img.shape[0],img.shape[1],4], dtype=np.uint8)\n",
        "\n",
        "   # 產生一組隨機值\n",
        "   sx = random.randrange(100,400,10) # 起始X座標\n",
        "   sy = random.randrange(100,300,10) # 起始Y座標\n",
        "   sw = random.randrange(50,200,10) # 方塊寬度\n",
        "   sh = random.randrange(50,200,10) # 方塊高度\n",
        "   sc = random.randrange(0,2,1) # 方塊型式及色彩\n",
        "\n",
        "   if(sc == 0):\n",
        "       # 隨意在影像上繪製一個紅色空心方框   \n",
        "       bgra = cv2.rectangle(bgra,(sx,sy),(sx+sw,sy+sh),(255,0,0),2)\n",
        "   else:\n",
        "       # 隨意在影像上繪製一個黃色實心方框\n",
        "       bgra = cv2.rectangle(bgra,(sx,sy),(sx+sw,sy+sh),(128,128,0),-1)\n",
        "\n",
        "   # 將有繪製圖案部份，透明層[3]設為完全不透明(255)\n",
        "   bgra[:,:,3] = (bgra.max(axis = 2) > 0 ).astype(int) * 255\n",
        "\n",
        "   return bgra"
      ],
      "metadata": {
        "id": "qxlA-mU5GadO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 將 OpenCV BGRA 格式影像轉換成可以覆疊回串流影像之base64格式\n",
        "\n",
        "輸入參數：  \n",
        "overlap_array : OpenCV BGRA 格式之輸入影像\n",
        "\n",
        "回返結果:  \n",
        "overlap_bytes : PIL RGBA 轉 base64 格式之輸出影像"
      ],
      "metadata": {
        "id": "RRp4rhzf3aG7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def overlap_to_bytes(overlap_array):\n",
        "  # 轉換 OpenCV BGRA 輸入格式到 PIL RGBA 格式\n",
        "  overlap_PIL = PIL.Image.fromarray(overlap_array, 'RGBA')\n",
        "  # 建立一個 io 緩衝區\n",
        "  iobuf = io.BytesIO()\n",
        "  # 將轉換好的 PIL RGBA 格式影像存成帶透明圖層 PNG 格式到 io 緩衝區\n",
        "  overlap_PIL.save(iobuf, format='png')\n",
        "  # 轉換成 base64 格式\n",
        "  overlap_bytes = 'data:image/png;base64,{}'.format((str(b64encode(iobuf.getvalue()), 'utf-8')))\n",
        "  \n",
        "  return overlap_bytes"
      ],
      "metadata": {
        "id": "oHFw3H8d3a_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 啟動網路攝影機連續取像並執行自定義影像處理程式\n",
        "\n",
        "執行過程中以滑鼠點擊影像即會中止程式。  "
      ],
      "metadata": {
        "id": "nf_gva1R6ktN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 啟動網路攝影機開始接收串流影像\n",
        "video_stream()\n",
        "# 設定串流影像文字標籤\n",
        "label_html = 'Capturing...'\n",
        "# 清空疊合影像內容\n",
        "overlap_img = ''\n",
        "\n",
        "# 執行取像、處理循環，執行過程中若於影像上按下滑鼠鍵即會中止程式\n",
        "while True:\n",
        "    # 從網路攝影機取得串流影像目前影格\n",
        "    js_reply = video_frame(label_html, overlap_img)\n",
        "\n",
        "    # 若無法取得影格則結束循環\n",
        "    if not js_reply:\n",
        "        break\n",
        "\n",
        "    # 將回傳的JavaScript影像物件轉成 OpenCV BGR 格式\n",
        "    img = js_to_image(js_reply[\"img\"])\n",
        "\n",
        "    # 呼叫自定義影像即時處理函式\n",
        "    overlap_array = realtime_process(img)\n",
        "\n",
        "    # 將覆疊影像轉換成 base64 格式\n",
        "    overlap_bytes = overlap_to_bytes(overlap_array)\n",
        "\n",
        "    # 更新覆疊影像到下一個影格\n",
        "    overlap_img = overlap_bytes"
      ],
      "metadata": {
        "id": "dYv-VjOty2A0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}